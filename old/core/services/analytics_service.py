"""
–°–µ—Ä–≤–∏—Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è KARMABOT1
–í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤, —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏ –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫—É
"""
import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
import json

from .cache import cache_service

logger = logging.getLogger(__name__)


@dataclass
class UserMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    total_users: int
    active_users_7d: int
    active_users_30d: int
    new_users_today: int
    new_users_7d: int
    new_users_30d: int
    avg_points_per_user: float
    top_users_by_points: List[Dict[str, Any]]


@dataclass
class PartnerMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤"""
    total_partners: int
    active_partners: int
    pending_partners: int
    approved_partners: int
    rejected_partners: int
    avg_cards_per_partner: float
    top_partners_by_cards: List[Dict[str, Any]]


@dataclass
class TransactionMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
    total_transactions: int
    transactions_today: int
    transactions_7d: int
    transactions_30d: int
    total_points_earned: int
    total_points_spent: int
    avg_transaction_value: float
    top_transaction_types: List[Dict[str, Any]]


@dataclass
class BusinessMetrics:
    """–ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏"""
    revenue_today: float
    revenue_7d: float
    revenue_30d: float
    conversion_rate: float
    retention_rate_7d: float
    retention_rate_30d: float
    avg_session_duration: float
    top_categories: List[Dict[str, Any]]


class AnalyticsService:
    """–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    
    def __init__(self):
        self.cache_ttl = 300  # 5 –º–∏–Ω—É—Ç –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
        self.is_initialized = False
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        if self.is_initialized:
            return
        
        try:
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            await self._create_analytics_indexes()
            self.is_initialized = True
            logger.info("üìä Analytics service initialized successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize analytics service: {e}")
    
    async def _create_analytics_indexes(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        try:
            from core.database.db_v2 import get_connection
            
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_users_created_at ON users(created_at)",
                "CREATE INDEX IF NOT EXISTS idx_users_last_active ON users(last_active)",
                "CREATE INDEX IF NOT EXISTS idx_partners_status ON partners_v2(status)",
                "CREATE INDEX IF NOT EXISTS idx_points_history_type ON points_history(transaction_type)",
                "CREATE INDEX IF NOT EXISTS idx_cards_category_status ON cards_v2(category_id, status)",
            ]
            
            with get_connection() as conn:
                for index_sql in indexes:
                    conn.execute(index_sql)
                conn.commit()
                logger.info("üìä Analytics indexes created")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to create analytics indexes: {e}")
    
    async def get_user_metrics(self, days: int = 30) -> UserMetrics:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        cache_key = f"analytics:user_metrics:{days}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = await cache_service.get(cache_key)
        if cached:
            data = json.loads(cached)
            return UserMetrics(**data)
        
        try:
            from core.database.db_v2 import get_connection
            
            with get_connection() as conn:
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
                cursor = conn.execute("SELECT COUNT(*) FROM users")
                total_users = cursor.fetchone()[0]
                
                # –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
                active_date = datetime.now() - timedelta(days=days)
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE last_active >= ?",
                    (active_date.isoformat(),)
                )
                active_users = cursor.fetchone()[0]
                
                # –ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE created_at >= ?",
                    (active_date.isoformat(),)
                )
                new_users = cursor.fetchone()[0]
                
                # –°—Ä–µ–¥–Ω–∏–µ –±–∞–ª–ª—ã –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                cursor = conn.execute("SELECT AVG(points_balance) FROM users")
                avg_points = cursor.fetchone()[0] or 0
                
                # –¢–æ–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø–æ –±–∞–ª–ª–∞–º
                cursor = conn.execute("""
                    SELECT telegram_id, username, first_name, points_balance 
                    FROM users 
                    ORDER BY points_balance DESC 
                    LIMIT 10
                """)
                top_users = [
                    {
                        'telegram_id': row[0],
                        'username': row[1],
                        'first_name': row[2],
                        'points_balance': row[3]
                    }
                    for row in cursor.fetchall()
                ]
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
                today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                week_ago = datetime.now() - timedelta(days=7)
                month_ago = datetime.now() - timedelta(days=30)
                
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE created_at >= ?",
                    (today.isoformat(),)
                )
                new_users_today = cursor.fetchone()[0]
                
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE created_at >= ?",
                    (week_ago.isoformat(),)
                )
                new_users_7d = cursor.fetchone()[0]
                
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE last_active >= ?",
                    (week_ago.isoformat(),)
                )
                active_users_7d = cursor.fetchone()[0]
                
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM users WHERE last_active >= ?",
                    (month_ago.isoformat(),)
                )
                active_users_30d = cursor.fetchone()[0]
                
                metrics = UserMetrics(
                    total_users=total_users,
                    active_users_7d=active_users_7d,
                    active_users_30d=active_users_30d,
                    new_users_today=new_users_today,
                    new_users_7d=new_users_7d,
                    new_users_30d=new_users,
                    avg_points_per_user=float(avg_points),
                    top_users_by_points=top_users
                )
                
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await cache_service.set(cache_key, json.dumps(metrics.__dict__), ex=self.cache_ttl)
                
                return metrics
                
        except Exception as e:
            logger.error(f"‚ùå Error getting user metrics: {e}")
            return UserMetrics(0, 0, 0, 0, 0, 0, 0.0, [])
    
    async def get_partner_metrics(self) -> PartnerMetrics:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤"""
        cache_key = "analytics:partner_metrics"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = await cache_service.get(cache_key)
        if cached:
            data = json.loads(cached)
            return PartnerMetrics(**data)
        
        try:
            from core.database.db_v2 import get_connection
            
            with get_connection() as conn:
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤
                cursor = conn.execute("SELECT COUNT(*) FROM partners_v2")
                total_partners = cursor.fetchone()[0]
                
                # –ü–∞—Ä—Ç–Ω–µ—Ä—ã –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
                cursor = conn.execute("SELECT status, COUNT(*) FROM partners_v2 GROUP BY status")
                status_counts = dict(cursor.fetchall())
                
                active_partners = status_counts.get('approved', 0)
                pending_partners = status_counts.get('pending', 0)
                rejected_partners = status_counts.get('rejected', 0)
                
                # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç –Ω–∞ –ø–∞—Ä—Ç–Ω–µ—Ä–∞
                cursor = conn.execute("""
                    SELECT AVG(card_count) FROM (
                        SELECT partner_id, COUNT(*) as card_count 
                        FROM cards_v2 
                        GROUP BY partner_id
                    )
                """)
                avg_cards = cursor.fetchone()[0] or 0
                
                # –¢–æ–ø –ø–∞—Ä—Ç–Ω–µ—Ä—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–∞—Ä—Ç
                cursor = conn.execute("""
                    SELECT p.display_name, p.tg_user_id, COUNT(c.id) as card_count
                    FROM partners_v2 p
                    LEFT JOIN cards_v2 c ON p.id = c.partner_id
                    GROUP BY p.id
                    ORDER BY card_count DESC
                    LIMIT 10
                """)
                top_partners = [
                    {
                        'display_name': row[0],
                        'tg_user_id': row[1],
                        'card_count': row[2]
                    }
                    for row in cursor.fetchall()
                ]
                
                metrics = PartnerMetrics(
                    total_partners=total_partners,
                    active_partners=active_partners,
                    pending_partners=pending_partners,
                    approved_partners=active_partners,
                    rejected_partners=rejected_partners,
                    avg_cards_per_partner=float(avg_cards),
                    top_partners_by_cards=top_partners
                )
                
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await cache_service.set(cache_key, json.dumps(metrics.__dict__), ex=self.cache_ttl)
                
                return metrics
                
        except Exception as e:
            logger.error(f"‚ùå Error getting partner metrics: {e}")
            return PartnerMetrics(0, 0, 0, 0, 0, 0.0, [])
    
    async def get_transaction_metrics(self, days: int = 30) -> TransactionMetrics:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
        cache_key = f"analytics:transaction_metrics:{days}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = await cache_service.get(cache_key)
        if cached:
            data = json.loads(cached)
            return TransactionMetrics(**data)
        
        try:
            from core.database.db_v2 import get_connection
            
            with get_connection() as conn:
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
                cursor = conn.execute("SELECT COUNT(*) FROM points_history")
                total_transactions = cursor.fetchone()[0]
                
                # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
                period_start = datetime.now() - timedelta(days=days)
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM points_history WHERE created_at >= ?",
                    (period_start.isoformat(),)
                )
                period_transactions = cursor.fetchone()[0]
                
                # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
                today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM points_history WHERE created_at >= ?",
                    (today.isoformat(),)
                )
                transactions_today = cursor.fetchone()[0]
                
                # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∑–∞ –Ω–µ–¥–µ–ª—é
                week_ago = datetime.now() - timedelta(days=7)
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM points_history WHERE created_at >= ?",
                    (week_ago.isoformat(),)
                )
                transactions_7d = cursor.fetchone()[0]
                
                # –û–±—â–∏–µ –±–∞–ª–ª—ã
                cursor = conn.execute("""
                    SELECT 
                        SUM(CASE WHEN change_amount > 0 THEN change_amount ELSE 0 END) as earned,
                        SUM(CASE WHEN change_amount < 0 THEN ABS(change_amount) ELSE 0 END) as spent
                    FROM points_history
                """)
                row = cursor.fetchone()
                total_points_earned = row[0] or 0
                total_points_spent = row[1] or 0
                
                # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                cursor = conn.execute("SELECT AVG(ABS(change_amount)) FROM points_history")
                avg_transaction_value = cursor.fetchone()[0] or 0
                
                # –¢–æ–ø —Ç–∏–ø—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
                cursor = conn.execute("""
                    SELECT transaction_type, COUNT(*) as count
                    FROM points_history
                    GROUP BY transaction_type
                    ORDER BY count DESC
                    LIMIT 10
                """)
                top_transaction_types = [
                    {'type': row[0], 'count': row[1]}
                    for row in cursor.fetchall()
                ]
                
                metrics = TransactionMetrics(
                    total_transactions=total_transactions,
                    transactions_today=transactions_today,
                    transactions_7d=transactions_7d,
                    transactions_30d=period_transactions,
                    total_points_earned=total_points_earned,
                    total_points_spent=total_points_spent,
                    avg_transaction_value=float(avg_transaction_value),
                    top_transaction_types=top_transaction_types
                )
                
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await cache_service.set(cache_key, json.dumps(metrics.__dict__), ex=self.cache_ttl)
                
                return metrics
                
        except Exception as e:
            logger.error(f"‚ùå Error getting transaction metrics: {e}")
            return TransactionMetrics(0, 0, 0, 0, 0, 0, 0.0, [])
    
    async def get_business_metrics(self, days: int = 30) -> BusinessMetrics:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏"""
        cache_key = f"analytics:business_metrics:{days}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = await cache_service.get(cache_key)
        if cached:
            data = json.loads(cached)
            return BusinessMetrics(**data)
        
        try:
            from core.database.db_v2 import get_connection
            
            with get_connection() as conn:
                # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–∞—Ä—Ç
                cursor = conn.execute("""
                    SELECT c.name, COUNT(cards.id) as card_count
                    FROM categories_v2 c
                    LEFT JOIN cards_v2 cards ON c.id = cards.category_id
                    WHERE c.is_active = 1
                    GROUP BY c.id
                    ORDER BY card_count DESC
                    LIMIT 10
                """)
                top_categories = [
                    {'name': row[0], 'card_count': row[1]}
                    for row in cursor.fetchall()
                ]
                
                # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
                metrics = BusinessMetrics(
                    revenue_today=0.0,  # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞—Å—á–µ—Ç –≤—ã—Ä—É—á–∫–∏
                    revenue_7d=0.0,
                    revenue_30d=0.0,
                    conversion_rate=0.0,  # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞—Å—á–µ—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
                    retention_rate_7d=0.0,  # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞—Å—á–µ—Ç —É–¥–µ—Ä–∂–∞–Ω–∏—è
                    retention_rate_30d=0.0,
                    avg_session_duration=0.0,  # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å–µ—Å—Å–∏–∏
                    top_categories=top_categories
                )
                
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await cache_service.set(cache_key, json.dumps(metrics.__dict__), ex=self.cache_ttl)
                
                return metrics
                
        except Exception as e:
            logger.error(f"‚ùå Error getting business metrics: {e}")
            return BusinessMetrics(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, [])
    
    async def get_dashboard_data(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            user_metrics, partner_metrics, transaction_metrics, business_metrics = await asyncio.gather(
                self.get_user_metrics(),
                self.get_partner_metrics(),
                self.get_transaction_metrics(),
                self.get_business_metrics()
            )
            
            return {
                'users': user_metrics.__dict__,
                'partners': partner_metrics.__dict__,
                'transactions': transaction_metrics.__dict__,
                'business': business_metrics.__dict__,
                'generated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error getting dashboard data: {e}")
            return {}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
analytics_service = AnalyticsService()


__all__ = [
    'AnalyticsService',
    'analytics_service',
    'UserMetrics',
    'PartnerMetrics', 
    'TransactionMetrics',
    'BusinessMetrics'
]
